# SUO-AWS: AWS News Subscription Platform

A serverless application that automatically scrapes AWS blog announcements, categorizes them using AI or URL-based logic, and emails subscribed users based on their selected AWS service categories.

## üèóÔ∏è Architecture Overview

SUO-AWS (Stay Updated On AWS) is built using a serverless architecture with the following AWS services:

- **AWS Lambda** - Three main functions: scraper, categorizer, and notifier.
- **Amazon DynamoDB** - Three tables for storing blog posts, user subscriptions, and categories
- **Amazon Bedrock** - Optional AI-powered categorization and summarization using Nova Pro model
- **Amazon S3** - Batch inference input/output storage
- **Amazon SNS** - Error notifications
- **API Gateway** - Direct integration with DynamoDB for user subscription management
- **Amazon Step Function** - Orchestrate functions workflow
- **Amazon EventBridge Scheduler** - Recurring, cron-based scheduler that processes SUO-AWS daily by triggering the step-function workflow every 24 hours.

_Note: The Project structure is the combination of all functions, codes and scripts in one folder for documentation purpose. The SAM template is only used for deploying the Notifier Lambda function._

## üìÅ Project Structure

```
suo-aws/
‚îú‚îÄ‚îÄ functions/
‚îÇ   ‚îú‚îÄ‚îÄ scraper/           # Web scraping AWS blogs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app.py         # Main Lambda handler
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ manual_extractor.py  # Playwright-based scraper
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ categorizer/       # AI/URL-based categorization
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app.py         # Main Lambda handler
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ batch_inference.py   # Bedrock batch processing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ url_categorizer.py   # URL-based categorization
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ notifier/          # Email notifications
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app.js         # Main Lambda handler (Node.js)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mail_setup.js  # Email configuration
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ package.json
‚îÇ   ‚îî‚îÄ‚îÄ subscribe/         # User subscription API
‚îÇ       ‚îú‚îÄ‚îÄ api-gateway-dynamodb.yaml
‚îÇ       ‚îî‚îÄ‚îÄ deploy-direct-integration.sh
‚îú‚îÄ‚îÄ template.yaml          # SAM template
‚îú‚îÄ‚îÄ samconfig.toml         # SAM configuration
‚îî‚îÄ‚îÄ README.md
```

## üöÄ Deployment

### Prerequisites

- AWS SAM CLI installed
- AWS CLI configured with appropriate credentials
- Python 3.10+ installed
- Node.js 18+ installed
- Docker

### Quick Start

1. **Clone the repository**
   ```bash
   git clone https://github.com/iAmSherifCodes/suo-aws.git
   cd suo-aws
   ```

2. **Install Playwright dependencies (for scraper)**
   ```bash
   cd functions/scraper
   pip install playwright
   playwright install chromium
   cd ../..
   ```
3. **Deploy the scraper function**
   ```bash
    cd functions/scraper
    chmod +x create_iam_role.sh
    ./create_iam_role.sh
    chmod +x deploy.sh
    ./deploy.sh
   ```

4. **Build the SAM application**
   ```bash
   sam build
   ```

5. **Deploy the application**
   ```bash
   sam deploy --guided
   ```

6. **Deploy the subscription API (optional)**
   ```bash
   cd functions/subscribe
   ./deploy-direct-integration.sh
   ```
  
7. **Deploy the Categorizer Function directly from the Console**
   ```bash
   cd functions/categorizer
   ./deploy-direct-integration.sh
   ```

### Environment Variables

The application uses the following environment variables:

| Variable | Description | Default |
|----------|-------------|---------|
| `POSTS_TABLE` | DynamoDB table for blog posts | `suo-aws-posts` |
| `USERS_TABLE` | DynamoDB table for users | `aws-suo-users` |
| `CATEGORIES_TABLE` | DynamoDB table for categories | `suo-categories` |
| `GENAI_MODEL` | Enable AI categorization | `false` |
| `BEDROCK_MODEL_ID` | Bedrock model for AI | `amazon.nova-lite-v1:0` |
| `EMAIL_USER` | SMTP username | - |
| `EMAIL_PASS` | SMTP password | - |
| `FROM_EMAIL` | Sender email address | - |

## üîß How It Works

### 1. **Web Scraping (Scraper Function)**
- Uses Playwright to scrape AWS blogs
- Extracts posts for a specific date (default: previous day)
- Stores raw blog post data in DynamoDB
- Handles pagination and dynamic content loading

### 2. **Categorization (Categorizer Function)**
- **URL-based**: Extracts category from blog URL path
- **AI-powered**: Uses Amazon Bedrock for intelligent categorization
- Supports batch processing for multiple posts
- Updates posts with category information

### 3. **Notification (Notifier Function)**
- Retrieves categorized posts for a date
- Matches posts with user subscriptions
- Sends personalized emails using SMTP
- Handles error notifications via SNS

### 4. **Subscription Management**
- Direct API Gateway to DynamoDB integration
- RESTful API for user subscription management
- Input validation and CORS support

## üìä Database Schema

### Posts Table (`suo-aws-posts`)
```json
{
  "id": "string (UUID)",
  "title": "string",
  "url": "string", 
  "author": "string",
  "date": "string (MM/DD/YYYY)",
  "description": "string",
  "category": "string",
  "summary": "string (optional)",
  "processed": "boolean"
}
```

### Users Table (`aws-suo-users`)
```json
{
  "id": "string (UUID)",
  "email": "string",
  "name": "string",
  "categories": ["string"],
  "active": "boolean",
  "created_at": "string"
}
```

### Categories Table (`suo-categories`)
```json
{
  "id": "string (UUID)",
  "date": "string (MM/DD/YYYY)",
  "categories": ["string"]
}
```

## üîå API Usage

### Subscribe to Categories
```bash
curl -X POST https://your-api-gateway-url/prod/subscribe \
  -H "Content-Type: application/json" \
  -d '{
    "name": "John Doe",
    "email": "john@example.com", 
    "categories": ["compute", "ai-ml", "serverless"]
  }'
```

### Manual Function Invocation

**Scraper Function:**
```bash
aws lambda invoke \
  --function-name suo-aws-scraper \
  --payload '{"target_date": "12/15/2024"}' \
  response.json
```

**Categorizer Function:**
```bash
aws lambda invoke \
  --function-name suo-aws-categorizer \
  --payload '{"date": "12/15/2024"}' \
  response.json
```

**Notifier Function:**
```bash
aws lambda invoke \
  --function-name suo-aws-notifier \
  --payload '{}' \
  response.json
```

## üéØ AWS Service Categories

The system recognizes these AWS service categories:
- `architecture`, `compute`, `containers`, `serverless`
- `database`, `storage`, `networking-and-content-delivery`
- `security`, `machine-learning`, `ai-ml`
- `analytics`, `big-data`, `business-intelligence`
- `developer`, `devops`, `mobile`
- `iot`, `media`, `gaming`
- And many more...

## üîç Monitoring & Troubleshooting

### CloudWatch Logs
- Each Lambda function creates its own log group
- Log levels can be controlled via `LOG_LEVEL` environment variable

### Error Handling
- SNS notifications for critical errors
- Comprehensive error logging
- Graceful degradation for non-critical failures

### Performance Optimization
- DynamoDB on-demand billing
- Lambda memory optimization (128MB default)
- Batch processing for AI operations

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## üìÑ License

This project is licensed under the MIT License - see the LICENSE file for details.

## üîó Repository

**Public Repository URL:** https://github.com/cashgraphicx/suo-aws-news-platform

> **Note:** Replace with your actual public repository URL after pushing to GitHub

---

*Built with ‚ù§Ô∏è using AWS Serverless technologies*
